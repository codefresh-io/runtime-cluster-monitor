- alert: PrometheusMemoryWarning
  expr: process_resident_memory_bytes{job="prom-prometheus-operator-prometheus",namespace="monitoring"} > 6300000000
  for: 10m
  labels:
    alertgroup: MemoryLow
    severity: warning
  annotations:
    message: 'prometheus: process_resident_memory_bytes = {{ $value }}'
    summary: Prometheus memory warning

- alert: ReminderCritical
  expr: label_replace(ALERTS{alertname!="ReminderCritical",alertstate="firing",severity="critical"}, "alert", "$1", "alertname", "(.*)") == 1
  for: 1h
  labels:
    alertgroup: reminder
    severity: critical
  annotations:
    message: '{{ $labels.alert }} {{ if $labels.node }}node={{ $labels.node }} {{ end }}{{ if $labels.pod }}pod={{ $labels.pod }} {{ end }}{{ if $labels.namespace }}ns={{ $labels.namespace }} {{ end }}{{ if $labels.service_name }}svc={{ $labels.service_name }}{{ end }}'
    summary: 'Reminder: there are critical alerts!'

- alert: AutoscalerMax
  expr: cluster_autoscaler_pool_max <= cluster_autoscaler_pool_target * 1.25 != 0
  labels:
    alertgroup: autoscaler
    severity: critical
  annotations:
    message: |
      autoscaler pool {{ $labels.name }} is close to maximum capability of {{ $value }}
      please consider enlarging the pool
    summary: 'autoscaler pool {{ $labels.name }} hit the ceiling'

- alert: AutoscalerExporterDown
  expr: absent(count(container_start_time_seconds{container="cluster-autoscaler-exporter",job="kubelet"}) == 1)
  for: 2m
  labels:
    alertgroup: downtime
    severity: critical
  annotations:
    message: cluster-autoscaler-exporter containers count != 1
    summary: cluster-autoscaler-exporter is down
